{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a simple Sequential Model from an LSTM. \n",
    "\n",
    "* Given a sequence of n-grams, the classifier predicts the following token as a class. \n",
    "* The input of the neural network is an array of sequences of tokens for the design matrix and the output a vector of labels that corresponds to the target token.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motivation\n",
    "\n",
    "In the case of the n-gram language model, we used the probability of each n-gram in the input sentence to calculate the perplexity. Our current model does not rely on n-grams, but on probabilities of sequences of tokens to be followed by a subsequent token. We need to adapt the perplexity formula for n-grams language models to sequence-based language models.\n",
    "\n",
    "If we consider the sentence of N tokens:\n",
    "\n",
    "$$w_{1},\\cdots, w_N$$\n",
    "\n",
    "Then we can calculate the probability of that sentence as the product of probabilities of all the padded subsequences. Let’s take an example of a 3-token sentence.\n",
    "\n",
    "$$ P(w_1,w_2, w_3) =  P(w_3 | w_1, w_2) \\times p(w_2 | w_1 ,0)  \\times p(w_1 | 0 ,0) $$\n",
    "\n",
    "In general, for a sentence of N tokens and a sequence length of length S,\n",
    "\n",
    "$$ P(w_1,\\cdots, w_N) = \\prod_{k = 1}^{ \\max{(N,S)}} P(w_k | \\text{padded}_S(w_{1}, \\cdots, w_{k-1})    )  $$\n",
    "\n",
    "where $ P(w_{k} | \\text{padded}_S(w_{1}, \\cdots, w_{k-1}) $ is precisely the probability given by the classification model.\n",
    "\n",
    "We can therefore compute the perplexity of a sentence of length N with\n",
    "\n",
    "$$PP(w_{1},\\cdots, w_N) = \\exp [ - \\frac{1}{N} {\\sum_{i = 1}^{ \\max{(N,S)} } \\log { P(w_{k} | \\text{padded}_S(w_{1}, \\cdots, w_{k-1}) } } ) ]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow\n",
    "\n",
    "#### Preparing the data\n",
    "\n",
    "1. Load the dataset that was prepared in task 1.\n",
    "2. The original dataset is too large and needs to be reduced. To reduce it, you can, for instance,\n",
    "   + filter out items that have too many or too little tokens,\n",
    "   + select items of a certain type: post, comments, or titles, or\n",
    "   + or sub sample items randomly.\n",
    "3. Build the vocabulary as the set of all unique tokens to construct the list of token indexes.\n",
    "  + Filtering on token frequency is one way to reduce the overall size of the vocabulary.\n",
    "4. Set a fixed sequence length and build sequences of token indexes from the corpus. (See for instance keras pad_sequences.)\n",
    "5. Split the sequences into predictors and labels (`keras.utils.to_categorical`)\n",
    "\n",
    "#### The model\n",
    "\n",
    "The data is now ready to be used to fit a neural network.\n",
    "\n",
    "1. Define a simple sequential model with an embedding layer, LSTM(s), and a dense layer with softmax activation. Feel free to experiment with dropouts, different optimizers. You can use any type of neural net you want; for example, Keras, TensorFlow, PyTorch, and so on.\n",
    "2. Specify the number of epochs, the batch size, and other fitting parameters.\n",
    "3. Fit the network.\n",
    "\n",
    "#### Assessing the results\n",
    "\n",
    "1. Write a function that generates text.\n",
    "2. Generate some text and take note of:\n",
    "  - Token repetitions\n",
    "  - Missing punctuations\n",
    "  - Other anomalies\n",
    "3. Write a function that calculates **perplexity of a sentence** and apply it to a subset of sentences to evaluate the model.\n",
    "4. Define a validation set; for instance, 1000 titles.\n",
    "5. Transform that validation set into sequences of tokens using the training vocabulary.\n",
    "6. Tune the neural net and the parameters of the preprocessing phase to improve the model’s perplexity score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References\n",
    "\n",
    "Fast.ai 2019\n",
    "\n",
    "* Lesson 4\n",
    "  - NLP classification - https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson3-imdb.ipynb\n",
    "  - https://youtu.be/qqt3aMPB81c?t=1038\n",
    "  - What's an Embedding - https://www.youtube.com/watch?v=GK1XhPM3K0g&feature=youtu.be&t=540\n",
    "    - project something into a higher dimensional space. int(s) -> vector of floats. \n",
    "* Lesson 12 (video snippets in the noteook.\n",
    "  - Preparing Text - https://github.com/fastai/course-v3/blob/master/nbs/dl2/12_text.ipynb\n",
    "  - AWD LSTM - https://github.com/fastai/course-v3/blob/master/nbs/dl2/12a_awd_lstm.ipynb\n",
    "  - Read in Wikitext to train LM - https://github.com/fastai/course-v3/blob/master/nbs/dl2/12b_lm_pretrain.ipynb\n",
    "  - UMLFIT - https://github.com/fastai/course-v3/blob/master/nbs/dl2/12c_ulmfit.ipynb\n",
    "\n",
    "When to reset or repackage the hidden state?\n",
    "  - Concept: stateless or stateful RNNs (this was a Keras thing)\n",
    "  - repackage / detach hidden weight tensors\n",
    "    - https://discuss.pytorch.org/t/solved-why-we-need-to-detach-variable-which-contains-hidden-representation/1426\n",
    "    - https://github.com/pytorch/examples/blob/master/word_language_model/main.py#L112\n",
    "    - deeplearning.ai lecture - https://www.youtube.com/watch?v=esgbmJ6SnSY\n",
    "\n",
    "Fast.ai 2018\n",
    "\n",
    "* https://forums.fast.ai/t/wiki-lesson-4/9402 (Intro NLP lesson)\n",
    "* https://forums.fast.ai/t/wiki-lesson-6/9404 (Follow up NLP lesson)\n",
    "* https://forums.fast.ai/t/wiki-lesson-7/9405 (Build Char RNN from scratch)\n",
    "  - repackage / state - https://youtu.be/H3g26EVADgY?t=660\n",
    "    + part of my confusion from what bptt means comes from this clip. He states that detaching is part of bptt. Not sure the are truly related. \n",
    "\n",
    "\n",
    "### RNN Notes\n",
    "\n",
    "* BPTT - backprop through time.  When you calculate the gradients the hidden activations (hidden state produced by the hidden layer) understand that it's loop over itself from the last input to the first. Therefore the computation graph grows linearly with each forward pass. To prevent vanishing gradients and not have a very large slow computation you need to `detach()` the hidden state from the computational graph. \n",
    "* sequence length - how long of a sequence the RNN will process when it processes a mini-batch. This is often the same size as BPTT but it doesn't have to be.  If you want to capture the loss of all inputs from the sequence in the minibatch then BPTT > seq_len \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOK_FILE= 'stackexchange_tokenized.csv'\n",
    "df = pd.read_csv(f'data/{TOK_FILE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the number of epochs, the batch size, and other fitting parameters\n",
    "\n",
    "seq_len = 50\n",
    "vocab_size = 4000\n",
    "embedding_dim = 200\n",
    "hidden_dim = 40\n",
    "batch_size = 15\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>post_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>length</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eliciting priors from experts</td>\n",
       "      <td>title</td>\n",
       "      <td>29</td>\n",
       "      <td>Eliciting priors from experts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What is normality?</td>\n",
       "      <td>title</td>\n",
       "      <td>18</td>\n",
       "      <td>What is normality ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What are some valuable Statistical Analysis op...</td>\n",
       "      <td>title</td>\n",
       "      <td>65</td>\n",
       "      <td>What are some valuable Statistical Analysis op...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Assessing the significance of differences in d...</td>\n",
       "      <td>title</td>\n",
       "      <td>58</td>\n",
       "      <td>Assessing the significance of differences in d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Two Cultures: statistics vs. machine learn...</td>\n",
       "      <td>title</td>\n",
       "      <td>50</td>\n",
       "      <td>The Two Cultures : statistics vs. machine lear...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  post_id  parent_id  comment_id  \\\n",
       "0           0        1        NaN         NaN   \n",
       "1           1        2        NaN         NaN   \n",
       "2           2        3        NaN         NaN   \n",
       "3           3        4        NaN         NaN   \n",
       "4           4        6        NaN         NaN   \n",
       "\n",
       "                                                text category  length  \\\n",
       "0                      Eliciting priors from experts    title      29   \n",
       "1                                 What is normality?    title      18   \n",
       "2  What are some valuable Statistical Analysis op...    title      65   \n",
       "3  Assessing the significance of differences in d...    title      58   \n",
       "4  The Two Cultures: statistics vs. machine learn...    title      50   \n",
       "\n",
       "                                           tokenized  \n",
       "0                      Eliciting priors from experts  \n",
       "1                                What is normality ?  \n",
       "2  What are some valuable Statistical Analysis op...  \n",
       "3  Assessing the significance of differences in d...  \n",
       "4  The Two Cultures : statistics vs. machine lear...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6473328"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11136"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['length'] > 4000].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7fb3fedc1080>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "df2 = df[df['length'] < 4000]\n",
    "df2.hist(column=\"length\", bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7fb3fb338908>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_post = df[df['category'] == 'post']\n",
    "df_title = df[df['category'] == 'title']\n",
    "df_comment = df[df['category'] == 'comment']\n",
    "\n",
    "df_post.hist(column=\"length\", bins=100)\n",
    "df_comment.hist(column=\"length\", bins=100)\n",
    "df_title.hist(column=\"length\", bins=100)\n",
    "\n",
    "# note that only posts have a long tail that get huge. \n",
    "# I would expect phrases to appear differently in long and short text. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the vocabularly from the set of unique tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fastai v1\n",
    "\n",
    "Letting Fast.ai do the tokenizing and numericalizing\n",
    "\n",
    "https://youtu.be/vnOpEwmtFJ8?t=5080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.6 s, sys: 1.81 s, total: 17.4 s\n",
      "Wall time: 53.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# TODO: consider a better way to combine values in the dataset. \n",
    "# Instead of just using text could you combine text and title? \n",
    "\n",
    "# if we use fast.ai we could do this\n",
    "tokenizer = Tokenizer()\n",
    "texts  = df['text'].values\n",
    "tokens = tokenizer.process_all(texts)\n",
    "\n",
    "#create tokens from a list of lists of tokens.  https://bit.ly/31xOsvf\n",
    "vocab = Vocab.create(tokens, max_vocab=vocab_size, min_freq=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntokens = [ vocab.numericalize(ta) for ta in tokens ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.4 s, sys: 383 ms, total: 17.8 s\n",
      "Wall time: 17.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ntok_tensors = [ torch.tensor(tka).type(torch.int64) for tka in ntokens ]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   5,  371,   45,  794,   79,    5, 1679, 1578,   30,  147,   35,  818,\n",
       "          44,  286,   40,   26])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ntok_tensors[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntok_tsr = torch.cat(ntok_tensors) #1D tensor. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick the right fixed sequence length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and test.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "corp_size = ntok_tsr.shape[0]\n",
    "indxs     = np.arange(corp_size)\n",
    "train_i, test_i = train_test_split(indxs, test_size=0.4, random_state=42)  \n",
    "test_i, valid_i = train_test_split(test_i, test_size=0.5, random_state=42)\n",
    "\n",
    "train_tsr = torch.gather(ntok_tsr, 0, torch.tensor(train_i))\n",
    "test_tsr  = torch.gather(ntok_tsr, 0, torch.tensor(test_i))\n",
    "valid_tsr = torch.gather(ntok_tsr, 0, torch.tensor(valid_i))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the sequence into predictors and labels\n",
    "\n",
    "\n",
    "\n",
    "# copied from https://bit.ly/2VyEJBa\n",
    "\n",
    "#expects a 1D tensor (all training, test, validation data) and a batch size. \n",
    "def batchify(data, bsz):\n",
    "    # Work out how cleanly we can divide the dataset into bsz parts.\n",
    "    nbatch = data.size(0) // bsz\n",
    "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
    "    data = data.narrow(0, 0, nbatch * bsz)\n",
    "    # Evenly divide the data across the bsz batches.\n",
    "    data = data.view(bsz, -1).t().contiguous()\n",
    "    #return data.to(device)\n",
    "    return data\n",
    "    \n",
    "def get_batch(source, i):\n",
    "    #seq_len = min(args.bptt, len(source) - 1 - i)\n",
    "    seq_len = len(source) - 1 - i\n",
    "    data = source[i:i+seq_len]\n",
    "    #target = source[i+1:i+1+seq_len].view(-1) #TODO: why reshape this? probably easier to run loss function. \n",
    "    target = source[i+1:i+1+seq_len]\n",
    "    return data, target\n",
    "\n",
    "\n",
    "\n",
    "### Notes:\n",
    "# example code has bptt as the sequence length\n",
    "# example code grabs bptt / seq_len rows at a time when processing a batch. Makes sense but feels strange\n",
    "# Question: does the example code ever reset the hidden weights? I don't think so. \n",
    "# - I would have thought this is where bptt would have hppened. \n",
    "# - alternatively you should reset at some point in `forward` https://bit.ly/2NNEY76\n",
    "\n",
    "# Do you want to create a dataloader or not? It could wrap a dataset with \"tokens\" variable.\n",
    "# see collate_fn, shuffle and batch_sampler arguments. \n",
    "# UPDATE: lots of interesting ideas in fast.ai \n",
    "# - create a collate_fn function that pads things - https://youtu.be/vnOpEwmtFJ8?t=6245 (fast.ai)\n",
    "# - create samplers that orders data for batching by size (or roughly by size)\n",
    "# - do batchify when you create a dataset. \n",
    "# - example dataset - https://youtu.be/vnOpEwmtFJ8?t=5786"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# there wasn't a really good reason to write this. You could get away without it.  \n",
    "class LMDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data, bsz, seq_len):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        data (Tensor): Rank 1 tensor with all numericalized data in it.     \n",
    "        \"\"\"\n",
    "        self.by_batch = batchify(data, bsz) \n",
    "        self.data = data\n",
    "        self.batch_size = bsz\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        xi = idx % self.batch_size\n",
    "        yi = idx // self.batch_size * seq_len\n",
    "        print(self.by_batch.shape)\n",
    "        source = self.by_batch[xi:xi+self.seq_len, yi]\n",
    "        target = self.by_batch[xi+1:xi+self.seq_len+1, yi]\n",
    "        return source, target\n",
    "        \n",
    "    #TODO: do you want to copy the batching function in here? \n",
    "    #remove this? \n",
    "    def get_batch(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "# LEFT OFF HERE.  If you want to create the dataloader you set shuffle to false and just instantiate one. \n",
    "# Debugging would have been easier if you numericalized as part of a transform. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmd = LMDataset(test_tsr, batch_size, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([764706, 15])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([   5,  143,   15,  466,   29,   12,    0,    5,    0,  100,   11,   28,\n",
       "           13,   14,  346,   14,  184,  396,   24,   16,   39,  192,    9,    6,\n",
       "           66,  450,  278,   13,   14,    5,   75,   12,    5,   13,  410,  731,\n",
       "          120,  128,   13,  383,    5,   68,    0,   97,  966,   17,    5, 3125,\n",
       "          167, 1024]),\n",
       " tensor([ 143,   15,  466,   29,   12,    0,    5,    0,  100,   11,   28,   13,\n",
       "           14,  346,   14,  184,  396,   24,   16,   39,  192,    9,    6,   66,\n",
       "          450,  278,   13,   14,    5,   75,   12,    5,   13,  410,  731,  120,\n",
       "          128,   13,  383,    5,   68,    0,   97,  966,   17,    5, 3125,  167,\n",
       "         1024,   13]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmd[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from rnn_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html\n",
    "### views in pytorch - https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view\n",
    "### Maybe skip this one - https://gist.github.com/williamFalcon/f27c7b90e34b4ba88ced042d9ef33edd\n",
    "### https://pytorch.org/docs/master/generated/torch.nn.LSTM.html\n",
    "### https://github.com/pytorch/examples/tree/master/word_language_model\n",
    "### https://stackoverflow.com/a/42482819 reshaping tensors with \"view\"\n",
    "### https://medium.com/@lankinen/fast-ai-lesson-12-notes-part-2-v3-dd53bec89c0b\n",
    "### - https://www.youtube.com/watch?v=vnOpEwmtFJ8&feature=emb_title\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, seq_len, vocab_size, embedding_dim, hidden_dim): #TODO: DO I NEED THE seq_len here? Doubt it. \n",
    "        \n",
    "        super(Net, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm =  nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.dense = nn.Linear(hidden_dim, vocab_size)\n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        \n",
    "        # decide how/when to reset and share hidden params? Consider bptt approach. \n",
    "        # - when you process inputs...\n",
    "        # x - review \"batchify\" and \"get_batch\" from - https://bit.ly/2VyEJBa so that you understand how they batch data and get labeels, etc.\n",
    "        # x - in prepping data for language models, do you need to pad anything? \n",
    "        # x  I don't believe so. I think 'batchify' combines sentences together. See `data.view(bsz, -1).t().contiguous()`\n",
    "        # x - figure out how bptt is used in the pytorch LM example code.  Why is it used in get_batch to limit the size? \n",
    "        # x - UPDATE: is this is the right question to ask? Perhaps you're really asking when to reset the hidden state \n",
    "        #     and how `detach()` works.\n",
    "        #   - NOTE: in `tokenize` from the pytorch example language model they tokenize and numericalize and return a 1D\n",
    "        #     tensor of the entire test, training or validation set. \n",
    "        # - NOTE: you built your vocab and numericalized with fast.ai. How to combine data together? \n",
    "        \n",
    "        seq_len, batch_size = x.shape   \n",
    "        x = self.word_embeddings(x)\n",
    "        x, hidden = self.lstm(x, hidden) # -> (seq_len, batch_size, hidden_size)\n",
    "        x = self.dense(x)                # -> (seq_len, batch_size, vocab_size)\n",
    "        x = F.log_softmax(x, dim=2)  #update. Do you want to predict one new thing here instead of a whole bunch?\n",
    "        #TODO: you could detach and return a new hidden state here. This is fine if you want bptt to always be seq_len.\n",
    "        return x, hidden \n",
    "        \n",
    "    # From - https://github.com/pytorch/examples/blob/e7870c1fd4706174f52a796521382c9342d4373f/word_language_model/model.py#L56\n",
    "    # https://discuss.pytorch.org/t/correct-way-to-declare-hidden-and-cell-states-of-lstm/15745\n",
    "    def init_hidden(self, bsz):\n",
    "        weight = next(self.parameters())\n",
    "        return (weight.new_zeros(1, bsz, self.hidden_dim), #right now just one layer is used.\n",
    "                weight.new_zeros(1, bsz, self.hidden_dim))\n",
    "   \n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        nn.init.uniform_(self.word_embeddings.weight, -initrange, initrange)\n",
    "        nn.init.zeros_(self.lstm.weight)\n",
    "        nn.init.uniform_(self.dense.weight, -initrange, initrange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(seq_len, vocab_size, embedding_dim, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 15])\n",
      "torch.Size([50, 15, 4000])\n"
     ]
    }
   ],
   "source": [
    "# run `forward` here to make sure that you have the expected dimensions for inputs and outputs.\n",
    "\n",
    "#fake input\n",
    "tsr = torch.randint(0,vocab_size, (seq_len, batch_size))\n",
    "print(tsr.shape)  \n",
    "\n",
    "out_tensor = net(tsr)\n",
    "print(out_tensor.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_data = batchify(train_tsr, batch_size)\n",
    "test_data  = batchify(test_tsr, batch_size)\n",
    "valid_data = batchify(valid_tsr, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "\n",
    "#LEFT OFF HERE -  review sample code from pytorch github and fill this out. \n",
    "# https://github.com/pytorch/examples/blob/master/word_language_model/main.py\n",
    "\n",
    "def train_epoch(model, train_data, seq_len):\n",
    "    \n",
    "    model.train()\n",
    "    hidden = model.init_hidden()\n",
    "    \n",
    "    train_rc = train_data.shape[0]\n",
    "    \n",
    "    #loop through all the batches in the epoch\n",
    "    for bi, sob in enumerate(range(0,train_rc, seq_len)):  \n",
    "        \n",
    "        data, test = get_batch(train_data, sob)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        \n",
    "        predicted, hidden = model(data,hidden)\n",
    "        hidden = hidden.detach() #TODO: if this works, consider just doing it in forward()\n",
    "        \n",
    "        #LEFT OFF HERE - you still need to define your loss function. Do you keep everything in the log space when calculating?\n",
    "        \n",
    "        #backward - calculate the gradient\n",
    "        #calculate the loss\n",
    "        #step - update the weights\n",
    "    pass\n",
    "\n",
    "def evaluate_epoch(model):\n",
    "    #calclate the loss\n",
    "    pass\n",
    "\n",
    "\n",
    "def training_loop(model, num_epochs):\n",
    "    \n",
    "    for i in range(num_epochs):\n",
    "        train_epoch(model)\n",
    "        evaluate_epoch(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a function that generates text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the function for errors (missing text, punctuation, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a validation set; for instance, 1000 titles.\n",
    "\n",
    "# consider not holding out data when you generate your LM. Okay for unsupervised learning. \n",
    "# https://youtu.be/qqt3aMPB81c?t=1266"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform that validation set into sequences of tokens using the training vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune the neural net and the parameters of the preprocessing phase to improve the model’s perplexity score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 30])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "emb = nn.Embedding(400, 30)\n",
    "tsr = torch.LongTensor([[1,2,4,5],[4,3,2,9]])\n",
    "ts2 = emb(tsr)\n",
    "ts2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 6, 9, 7],\n",
       "        [3, 6, 8, 7],\n",
       "        [0, 8, 9, 0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how to get random tensors that are integers\n",
    "torch.randint(0,10, (3,4,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied code from https://github.com/pytorch/examples/tree/master/word_language_model\n",
    "# testing model dimensions. \n",
    "rnn_lm = RNNModel('LSTM', vocab_size, seq_len, embedding_dim, 1, dropout=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([750, 4000])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden = rnn_lm.init_hidden(batch_size)\n",
    "out_tensor, _ = rnn_lm(tsr, hidden)\n",
    "out_tensor.shape #same output size as my model. **update** they do this intentionally for easy loss calculations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 15, 4000])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_out = torch.randint(0,vocab_size, (seq_len, batch_size, vocab_size)).float()\n",
    "#rszd_out = lstm_out.view(seq_len, batch_size, -1) #this is a noop. \n",
    "rszd_out = F.softmax(rszd_out, dim=2) #removed log\n",
    "rszd_out.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sanity check\n",
    "summed = torch.sum(rszd_out, dim=2)\n",
    "summed[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2152,  453, 2541, 3116],\n",
       "         [1831, 3638, 2561, 1046],\n",
       "         [1450, 2765, 3805, 1294]],\n",
       "\n",
       "        [[3281, 2037,  266, 3607],\n",
       "         [3907, 2355, 3675, 1584],\n",
       "         [3511, 2891, 3937, 2514]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(0,vocab_size, (2, 3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### testing batchify and get_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsr  = torch.LongTensor([1,2,4,5,4,3,2,9, 3, 8, 7, 6])\n",
    "tsr2 = torch.arange(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = batchify(tsr, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 5, 2, 8],\n",
       "        [2, 4, 9, 7],\n",
       "        [4, 3, 3, 6]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3 = batchify(tsr2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 4, 9, 7])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2[1] #didn't realize this style of indexing worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2, 4, 9, 7]]), tensor([[4, 3, 3, 6]]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batch(t2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1, 13, 25, 37],\n",
       "         [ 2, 14, 26, 38],\n",
       "         [ 3, 15, 27, 39],\n",
       "         [ 4, 16, 28, 40],\n",
       "         [ 5, 17, 29, 41],\n",
       "         [ 6, 18, 30, 42],\n",
       "         [ 7, 19, 31, 43],\n",
       "         [ 8, 20, 32, 44],\n",
       "         [ 9, 21, 33, 45],\n",
       "         [10, 22, 34, 46]]), tensor([[ 2, 14, 26, 38],\n",
       "         [ 3, 15, 27, 39],\n",
       "         [ 4, 16, 28, 40],\n",
       "         [ 5, 17, 29, 41],\n",
       "         [ 6, 18, 30, 42],\n",
       "         [ 7, 19, 31, 43],\n",
       "         [ 8, 20, 32, 44],\n",
       "         [ 9, 21, 33, 45],\n",
       "         [10, 22, 34, 46],\n",
       "         [11, 23, 35, 47]]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batch(t3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
